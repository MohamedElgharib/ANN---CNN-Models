{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_o2L3Io9t4c"
   },
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "We already know how neural networks work so we can skip through the basics and move right into explaining the following concepts.\n",
    "- Image Data\n",
    "- Convolutional Layer\n",
    "- Pooling Layer\n",
    "- CNN Architectures\n",
    "\n",
    "The major differences we are about to see in these types of neural networks are the layers that make them up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqLsm2XzNQSE"
   },
   "source": [
    "\n",
    "## Dataset\n",
    "It contains 60,000 32x32 color images with 6000 images of each class. \n",
    "\n",
    "The labels in this dataset are the following:\n",
    "- Airplane\n",
    "- Automobile\n",
    "- Bird\n",
    "- Cat\n",
    "- Deer\n",
    "- Dog\n",
    "- Frog\n",
    "- Horse\n",
    "- Ship\n",
    "- Truck\n",
    "\n",
    "We'll load the dataset and have a look at some of the images below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bnIbwiK7Ohv2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD AND SPLIT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "49wbEaM1PCCR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 364s 2us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Bp0yAAcuPHFN"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at a one image\n",
    "IMG_INDEX = 6\n",
    "\n",
    "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
    "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPqeddhcPwpc"
   },
   "source": [
    "## CNN Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ibuJZqAXQrWJ"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tybTBoi_Qtxl"
   },
   "source": [
    "**Layer 1**\n",
    "\n",
    "The input shape of our data will be 32, 32, 3 and we will process 32 filters of size 3x3 over our input data. We will also apply the activation function relu to the output of each convolution operation.\n",
    "\n",
    "**Layer 2**\n",
    "\n",
    "This layer will perform the max pooling operation using 2x2 samples and a stride of 2.\n",
    "\n",
    "**Other Layers**\n",
    "\n",
    "The next set of layers do very similar things but take as input the feature map from the previous layer. They also increase the frequency of filters from 32 to 64. We can do this as our data shrinks in spacial dimensions as it passed through the layers, meaning we can afford (computationally) to add more depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_QahwuduSEDG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 56,320\n",
      "Trainable params: 56,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # let's have a look at our model so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXw-sreaSzTW"
   },
   "source": [
    "After looking at the summary you should notice that the depth of our image increases but the spacial dimensions reduce drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjtADcfmSI9q"
   },
   "source": [
    "## Adding Dense Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "A9TMZH_oSULo"
   },
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fEzHX-7ESeCl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxfqtdDbSf4W"
   },
   "source": [
    "We can see that the flatten layer changes the shape of our data so that we can feed it to the 64-node dense layer, follwed by the final output layer of 10 neurons (one for each class).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdPxFvHdTLRK"
   },
   "source": [
    "## Training\n",
    "Now we will train and compile the model using the recommended hyper paramaters from tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "5loIug93TW1E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 298s 6ms/sample - loss: 0.8734 - accuracy: 0.6930 - val_loss: 0.9291 - val_accuracy: 0.6800\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 297s 6ms/sample - loss: 0.8128 - accuracy: 0.7137 - val_loss: 0.9039 - val_accuracy: 0.6877\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=2, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkdRKQnETgLv"
   },
   "source": [
    "## Evaluating the Model\n",
    "We can determine how well the model performed by looking at it's performance on the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6I2vJFiiTkQE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 16s - loss: 0.9039 - accuracy: 0.6877\n",
      "0.6877\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lKwDlvvUbIm"
   },
   "source": [
    "You should be getting an accuracy of about 70%. This isn't bad for a simple model like this, but we'll dive into some better approaches for computer vision below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.2262464e+00 -1.8654361e-01 -7.4402615e-04 ... -2.9441288e+00\n",
      "   6.8439978e-01 -1.2193447e+00]\n",
      " [ 4.7510328e+00  1.0998585e+01 -6.8841701e+00 ... -1.0481359e+01\n",
      "   1.2195443e+01  4.0601678e+00]\n",
      " [ 2.2024333e+00  4.3478913e+00 -1.4051170e+00 ... -4.0623827e+00\n",
      "   4.0543070e+00  3.0004339e+00]\n",
      " ...\n",
      " [-3.3265793e+00 -6.9143348e+00  8.7811089e-01 ...  2.2248712e+00\n",
      "  -3.0316877e+00 -5.3263335e+00]\n",
      " [-4.9570996e-01  1.8392969e+00  5.4260963e-01 ... -2.0439241e+00\n",
      "  -3.5486519e+00 -2.7656658e+00]\n",
      " [-4.1902065e+00 -4.1291866e+00 -7.4531895e-01 ...  5.8107505e+00\n",
      "  -6.4606838e+00 -5.6545830e+00]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Computer Vision.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
